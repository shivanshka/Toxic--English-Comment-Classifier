{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_tpu_or_gpu(device: str='gpu'):\n",
    "    if device.lower() == 'gpu':\n",
    "        print(\"Setting up GPU.....\")\n",
    "        device_name = tf.test.gpu_device_name()\n",
    "        if \"GPU\" not in device_name:\n",
    "            print(\"GPU device not found\")\n",
    "        print('Found GPU at: {}'.format(device_name))\n",
    "        \n",
    "        config = tf.compat.v1.ConfigProto() \n",
    "        config.gpu_options.allow_growth = True \n",
    "        sess = tf.compat.v1.Session(config=config) \n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "        \n",
    "        print(config)\n",
    "    \n",
    "    elif device.lower() == 'tpu':\n",
    "        print(\"Setting up TPU.....\")\n",
    "        try:\n",
    "            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "            print('Running on TPU ', tpu.master())\n",
    "        except ValueError:\n",
    "            tpu = None\n",
    "\n",
    "        if tpu:\n",
    "            tf.config.experimental_connect_to_cluster(tpu)\n",
    "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "            tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        else:\n",
    "            tpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "        print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        raise Exception(\"Wrong Device Paramter Passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tpu_or_gpu(device='tpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "print('Running on TPU ', tpu.master())\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import tensorflow as tf\n",
    "#import tensorflow_gpu\n",
    "import urllib\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True \n",
    "sess = tf.compat.v1.Session(config=config) \n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:58:45.308317Z",
     "iopub.status.busy": "2023-05-02T03:58:45.307445Z",
     "iopub.status.idle": "2023-05-02T03:58:45.312279Z",
     "shell.execute_reply": "2023-05-02T03:58:45.311351Z",
     "shell.execute_reply.started": "2023-05-02T03:58:45.308281Z"
    }
   },
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/nicknochnack/CommentToxicity/main/jigsaw-toxic-comment-classification-challenge/train.csv/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:58:49.842202Z",
     "iopub.status.busy": "2023-05-02T03:58:49.841469Z",
     "iopub.status.idle": "2023-05-02T03:58:51.105389Z",
     "shell.execute_reply": "2023-05-02T03:58:51.104041Z",
     "shell.execute_reply.started": "2023-05-02T03:58:49.842169Z"
    }
   },
   "outputs": [],
   "source": [
    "data =urllib.request.urlretrieve(URL, filename=\"toxic_comment_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:58:53.270452Z",
     "iopub.status.busy": "2023-05-02T03:58:53.270037Z",
     "iopub.status.idle": "2023-05-02T03:58:54.160713Z",
     "shell.execute_reply": "2023-05-02T03:58:54.159226Z",
     "shell.execute_reply.started": "2023-05-02T03:58:53.270420Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/working/toxic_comment_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:58:58.134669Z",
     "iopub.status.busy": "2023-05-02T03:58:58.134201Z",
     "iopub.status.idle": "2023-05-02T03:58:58.150994Z",
     "shell.execute_reply": "2023-05-02T03:58:58.149991Z",
     "shell.execute_reply.started": "2023-05-02T03:58:58.134630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic   \n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0  \\\n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:00.582407Z",
     "iopub.status.busy": "2023-05-02T03:59:00.581942Z",
     "iopub.status.idle": "2023-05-02T03:59:00.622018Z",
     "shell.execute_reply": "2023-05-02T03:59:00.620710Z",
     "shell.execute_reply.started": "2023-05-02T03:59:00.582372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:01.912897Z",
     "iopub.status.busy": "2023-05-02T03:59:01.912478Z",
     "iopub.status.idle": "2023-05-02T03:59:01.946953Z",
     "shell.execute_reply": "2023-05-02T03:59:01.945680Z",
     "shell.execute_reply.started": "2023-05-02T03:59:01.912866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:07.302399Z",
     "iopub.status.busy": "2023-05-02T03:59:07.301981Z",
     "iopub.status.idle": "2023-05-02T03:59:07.322099Z",
     "shell.execute_reply": "2023-05-02T03:59:07.321054Z",
     "shell.execute_reply.started": "2023-05-02T03:59:07.302367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic value count\n",
      "--------------------\n",
      "0: 144277 | 90.42 %\n",
      "1: 15294 | 9.58 %\n",
      "\n",
      "severe_toxic value count\n",
      "--------------------\n",
      "0: 157976 | 99.0 %\n",
      "1: 1595 | 1.0 %\n",
      "\n",
      "obscene value count\n",
      "--------------------\n",
      "0: 151122 | 94.71 %\n",
      "1: 8449 | 5.29 %\n",
      "\n",
      "threat value count\n",
      "--------------------\n",
      "0: 159093 | 99.7 %\n",
      "1: 478 | 0.3 %\n",
      "\n",
      "insult value count\n",
      "--------------------\n",
      "0: 151694 | 95.06 %\n",
      "1: 7877 | 4.94 %\n",
      "\n",
      "identity_hate value count\n",
      "--------------------\n",
      "0: 158166 | 99.12 %\n",
      "1: 1405 | 0.88 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in data.columns:\n",
    "    if data[column].dtype != 'O':\n",
    "        value_count = data[column].value_counts()\n",
    "        print(f\"{column} value count\\n{'--'*10}\")\n",
    "        print(f\"0: {value_count[0]} | {round((value_count[0]/data.shape[0])*100,2)} %\\n\"\n",
    "              f\"1: {value_count[1]} | {round((value_count[1]/data.shape[0])*100,2)} %\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text_len\"] = data[\"comment_text\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"text_len\"]==data[\"text_len\"].max()]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:23.258385Z",
     "iopub.status.busy": "2023-05-02T03:59:23.257726Z",
     "iopub.status.idle": "2023-05-02T03:59:23.269007Z",
     "shell.execute_reply": "2023-05-02T03:59:23.267719Z",
     "shell.execute_reply.started": "2023-05-02T03:59:23.258349Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data['comment_text']\n",
    "y = data[data.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:28.032940Z",
     "iopub.status.busy": "2023-05-02T03:59:28.031607Z",
     "iopub.status.idle": "2023-05-02T03:59:28.041334Z",
     "shell.execute_reply": "2023-05-02T03:59:28.040224Z",
     "shell.execute_reply.started": "2023-05-02T03:59:28.032896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:29.290271Z",
     "iopub.status.busy": "2023-05-02T03:59:29.289256Z",
     "iopub.status.idle": "2023-05-02T03:59:29.297414Z",
     "shell.execute_reply": "2023-05-02T03:59:29.296210Z",
     "shell.execute_reply.started": "2023-05-02T03:59:29.290225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:33.949995Z",
     "iopub.status.busy": "2023-05-02T03:59:33.948913Z",
     "iopub.status.idle": "2023-05-02T03:59:35.543774Z",
     "shell.execute_reply": "2023-05-02T03:59:35.542274Z",
     "shell.execute_reply.started": "2023-05-02T03:59:33.949947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet2022 to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet2022.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/usr/share/nltk_data/corpora/wordnet2022': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet2022')\n",
    "!cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:41.504899Z",
     "iopub.status.busy": "2023-05-02T03:59:41.504457Z",
     "iopub.status.idle": "2023-05-02T03:59:41.518383Z",
     "shell.execute_reply": "2023-05-02T03:59:41.517276Z",
     "shell.execute_reply.started": "2023-05-02T03:59:41.504864Z"
    }
   },
   "outputs": [],
   "source": [
    "class Text_Cleaner:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.STOPWORDS = stopwords.words('english')\n",
    "        self.wordnet = WordNetLemmatizer()\n",
    "        \n",
    "    def new_line_code(self, x:str)->str:\n",
    "        pattern = \"\\n\"\n",
    "        x = re.sub(pattern,' ', x).strip().lower()\n",
    "        return x\n",
    "\n",
    "    def remove_punctuations(self, x:str)->str:\n",
    "        x = x.translate(str.maketrans('','',string.punctuation))\n",
    "        return x\n",
    "\n",
    "    def remove_stopwords(self, x:str)->str:\n",
    "        sent=[]\n",
    "        for word in x.split():\n",
    "            if word not in self.STOPWORDS:\n",
    "                sent.append(word)\n",
    "        return ' '.join(sent)\n",
    "\n",
    "    def lemmatization(self, x:str)->str:\n",
    "        sent=[]\n",
    "        for word in x.split():\n",
    "            sent.append(self.wordnet.lemmatize(word))\n",
    "        return ' '.join(sent)\n",
    "    \n",
    "    def clean_text(self):\n",
    "        self.data = self.data.apply(self.new_line_code)\n",
    "        self.data = self.data.apply(self.remove_punctuations)\n",
    "        self.data = self.data.apply(self.remove_stopwords)\n",
    "        self.data = self.data.apply(self.lemmatization)\n",
    "        self.data = self.data.apply(lambda x: x.strip())\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T03:59:49.018680Z",
     "iopub.status.busy": "2023-05-02T03:59:49.018225Z",
     "iopub.status.idle": "2023-05-02T04:01:05.309702Z",
     "shell.execute_reply": "2023-05-02T04:01:05.308530Z",
     "shell.execute_reply.started": "2023-05-02T03:59:49.018645Z"
    }
   },
   "outputs": [],
   "source": [
    "X = Text_Cleaner(X).clean_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T04:01:24.434536Z",
     "iopub.status.busy": "2023-05-02T04:01:24.433580Z",
     "iopub.status.idle": "2023-05-02T04:01:24.443083Z",
     "shell.execute_reply": "2023-05-02T04:01:24.442120Z",
     "shell.execute_reply.started": "2023-05-02T04:01:24.434499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation edits made username hardcore metal...\n",
       "1         daww match background colour im seemingly stuc...\n",
       "2         hey man im really trying edit war guy constant...\n",
       "3         cant make real suggestion improvement wondered...\n",
       "4                       sir hero chance remember page thats\n",
       "                                ...                        \n",
       "159566    second time asking view completely contradicts...\n",
       "159567       ashamed horrible thing put talk page 128611993\n",
       "159568    spitzer umm there actual article prostitution ...\n",
       "159569    look like actually put speedy first version de...\n",
       "159570    really dont think understand came idea bad rig...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:58:39.921852Z",
     "iopub.status.busy": "2023-05-02T05:58:39.920835Z",
     "iopub.status.idle": "2023-05-02T05:58:39.927364Z",
     "shell.execute_reply": "2023-05-02T05:58:39.926074Z",
     "shell.execute_reply.started": "2023-05-02T05:58:39.921812Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    VOCAB_SIZE = 200000\n",
    "    OUTPUT_DIM = 1800\n",
    "    BUFFER_SIZE = 160000\n",
    "    BATCH_SIZE = 16*8\n",
    "    EPOCHS = 10\n",
    "    BASE_LOG_DIR = \"log_dir\"\n",
    "    CHECKPOINT_DIR = os.path.join(BASE_LOG_DIR,\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:58:42.901376Z",
     "iopub.status.busy": "2023-05-02T05:58:42.900350Z",
     "iopub.status.idle": "2023-05-02T05:58:42.914750Z",
     "shell.execute_reply": "2023-05-02T05:58:42.913372Z",
     "shell.execute_reply.started": "2023-05-02T05:58:42.901337Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=Config.VOCAB_SIZE,\n",
    "                               output_sequence_length=Config.OUTPUT_DIM,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:58:47.181294Z",
     "iopub.status.busy": "2023-05-02T05:58:47.180206Z",
     "iopub.status.idle": "2023-05-02T05:58:53.323100Z",
     "shell.execute_reply": "2023-05-02T05:58:53.321615Z",
     "shell.execute_reply.started": "2023-05-02T05:58:47.181257Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:58:55.847062Z",
     "iopub.status.busy": "2023-05-02T05:58:55.846199Z",
     "iopub.status.idle": "2023-05-02T05:58:58.522697Z",
     "shell.execute_reply": "2023-05-02T05:58:58.521187Z",
     "shell.execute_reply.started": "2023-05-02T05:58:55.847022Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:59:01.742933Z",
     "iopub.status.busy": "2023-05-02T05:59:01.741867Z",
     "iopub.status.idle": "2023-05-02T05:59:01.761677Z",
     "shell.execute_reply": "2023-05-02T05:59:01.760395Z",
     "shell.execute_reply.started": "2023-05-02T05:59:01.742896Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(Config.BUFFER_SIZE)\n",
    "dataset = dataset.batch(Config.BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:59:05.696783Z",
     "iopub.status.busy": "2023-05-02T05:59:05.695899Z",
     "iopub.status.idle": "2023-05-02T05:59:05.704363Z",
     "shell.execute_reply": "2023-05-02T05:59:05.703055Z",
     "shell.execute_reply.started": "2023-05-02T05:59:05.696741Z"
    }
   },
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*0.8))\n",
    "val = dataset.skip(int(len(dataset)*0.8)).take(int(len(dataset)*0.2))\n",
    "#test = dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:59:15.120769Z",
     "iopub.status.busy": "2023-05-02T05:59:15.119952Z",
     "iopub.status.idle": "2023-05-02T05:59:15.127808Z",
     "shell.execute_reply": "2023-05-02T05:59:15.126504Z",
     "shell.execute_reply.started": "2023-05-02T05:59:15.120734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:59:35.957940Z",
     "iopub.status.busy": "2023-05-02T05:59:35.956917Z",
     "iopub.status.idle": "2023-05-02T05:59:35.964417Z",
     "shell.execute_reply": "2023-05-02T05:59:35.963156Z",
     "shell.execute_reply.started": "2023-05-02T05:59:35.957899Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    LAYERS = [\n",
    "              Embedding(Config.VOCAB_SIZE+1, 32),\n",
    "              Bidirectional(LSTM(64, activation='tanh', return_sequences=True)),\n",
    "              Bidirectional(LSTM(32)),\n",
    "              Dense(128, activation='relu'),\n",
    "              Dense(256, activation='relu'),\n",
    "              Dense(128, activation='relu'),\n",
    "              Dense(6, activation='sigmoid')]\n",
    "    \n",
    "    model = Sequential(LAYERS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:57:41.188889Z",
     "iopub.status.busy": "2023-05-02T05:57:41.187755Z",
     "iopub.status.idle": "2023-05-02T05:57:41.195823Z",
     "shell.execute_reply": "2023-05-02T05:57:41.194570Z",
     "shell.execute_reply.started": "2023-05-02T05:57:41.188851Z"
    }
   },
   "outputs": [],
   "source": [
    "def callbacks(base_dir=\".\"):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "    ckpt_file = os.path.join(Config.CHECKPOINT_DIR,\"model\")\n",
    "    os.makedirs(ckpt_file,exist_ok=True)\n",
    "\n",
    "    ckpt_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "      filepath = ckpt_file,\n",
    "      save_best_only = True)\n",
    "\n",
    "    callback_list = [early_stopping,\n",
    "                     ckpt_cb]\n",
    "    return callback_list\n",
    "callbacks_list = callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:59:41.371024Z",
     "iopub.status.busy": "2023-05-02T05:59:41.370219Z",
     "iopub.status.idle": "2023-05-02T05:59:43.045257Z",
     "shell.execute_reply": "2023-05-02T05:59:43.043872Z",
     "shell.execute_reply.started": "2023-05-02T05:59:41.370984Z"
    }
   },
   "outputs": [],
   "source": [
    "with tpu_strategy.scope():\n",
    "    model = create_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                  loss=tf.keras.losses.binary_crossentropy,\n",
    "                  metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:59:46.873265Z",
     "iopub.status.busy": "2023-05-02T05:59:46.872125Z",
     "iopub.status.idle": "2023-05-02T05:59:46.897653Z",
     "shell.execute_reply": "2023-05-02T05:59:46.896516Z",
     "shell.execute_reply.started": "2023-05-02T05:59:46.873222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, None, 128)        49664     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,565,926\n",
      "Trainable params: 6,565,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:59:52.944840Z",
     "iopub.status.busy": "2023-05-02T05:59:52.943763Z",
     "iopub.status.idle": "2023-05-02T05:59:52.951415Z",
     "shell.execute_reply": "2023-05-02T05:59:52.950253Z",
     "shell.execute_reply.started": "2023-05-02T05:59:52.944797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T05:59:56.694087Z",
     "iopub.status.busy": "2023-05-02T05:59:56.693112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 06:00:10.332459: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2023-05-02 06:00:10.597457: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.8734"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 06:19:39.587529: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2023-05-02 06:19:39.748695: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_dir/models/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_dir/models/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 1228s 1s/step - loss: 0.1443 - accuracy: 0.8734 - val_loss: 0.0638 - val_accuracy: 0.9949\n",
      "Epoch 2/10\n",
      "997/997 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_dir/models/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: log_dir/models/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997/997 [==============================] - 1206s 1s/step - loss: 0.0582 - accuracy: 0.9941 - val_loss: 0.0511 - val_accuracy: 0.9943\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train, \n",
    "                    epochs=Config.EPOCHS,\n",
    "                    steps_per_epoch=len(train),\n",
    "                    validation_data=val, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, test_data):\n",
    "    pre = Precision()\n",
    "    re = Recall()\n",
    "    acc = CategoricalAccuracy()\n",
    "    \n",
    "    for batch in test_data.as_numpy_iterator():\n",
    "        X_true, y_true = batch\n",
    "        y_pred= model.predict(X_true)\n",
    "        \n",
    "        y_true = y_true.flatten()\n",
    "        y_pred = y_pred.flatten()\n",
    "        \n",
    "        pre.update_state(y_true, y_pred)\n",
    "        re.update_state(y_true, y_pred)\n",
    "        acc.update_state(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Precision: {pre.result().numpy()}\\nRecall: {re.result().numpy()}\\nAccuracy: {acc.result().numpy()}\")\n",
    "    return (pre.result().numpy(), re.result().numpy(), acc.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=model_evaluation(model=model, test_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_evaluation(model=model, test_data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
