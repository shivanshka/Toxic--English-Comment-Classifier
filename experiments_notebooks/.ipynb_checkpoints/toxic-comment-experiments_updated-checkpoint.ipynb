{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:20:49.587602Z",
     "iopub.status.busy": "2023-05-03T13:20:49.587243Z",
     "iopub.status.idle": "2023-05-03T13:20:58.848209Z",
     "shell.execute_reply": "2023-05-03T13:20:58.847069Z",
     "shell.execute_reply.started": "2023-05-03T13:20:49.587572Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import tensorflow as tf\n",
    "#import tensorflow_gpu\n",
    "import urllib\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy, AUC\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:21:32.956793Z",
     "iopub.status.busy": "2023-05-03T13:21:32.955526Z",
     "iopub.status.idle": "2023-05-03T13:21:32.966201Z",
     "shell.execute_reply": "2023-05-03T13:21:32.965160Z",
     "shell.execute_reply.started": "2023-05-03T13:21:32.956751Z"
    }
   },
   "outputs": [],
   "source": [
    "def tf_tpu_or_gpu(device: str='gpu'):\n",
    "    if device.lower() == 'gpu':\n",
    "        print(\"Setting up GPU.....\")\n",
    "        device_name = tf.test.gpu_device_name()\n",
    "        if \"GPU\" not in device_name:\n",
    "            print(\"GPU device not found\")\n",
    "        print('Found GPU at: {}'.format(device_name))\n",
    "        \n",
    "        config = tf.compat.v1.ConfigProto() \n",
    "        config.gpu_options.allow_growth = True \n",
    "        sess = tf.compat.v1.Session(config=config) \n",
    "        tf.compat.v1.keras.backend.set_session(sess)\n",
    "        \n",
    "        print(config)\n",
    "    \n",
    "    elif device.lower() == 'tpu':\n",
    "        print(\"Setting up TPU.....\")\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        print('Running on TPU ', tpu.master())\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print(\"REPLICAS: \", tpu_strategy.num_replicas_in_sync)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Wrong Device Paramter Passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:21:37.410872Z",
     "iopub.status.busy": "2023-05-03T13:21:37.410504Z",
     "iopub.status.idle": "2023-05-03T13:21:40.078927Z",
     "shell.execute_reply": "2023-05-03T13:21:40.077789Z",
     "shell.execute_reply.started": "2023-05-03T13:21:37.410839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up GPU.....\n",
      "Found GPU at: /device:GPU:0\n",
      "gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_tpu_or_gpu(device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:16:59.910818Z",
     "iopub.status.busy": "2023-05-03T13:16:59.909809Z",
     "iopub.status.idle": "2023-05-03T13:17:06.393155Z",
     "shell.execute_reply": "2023-05-03T13:17:06.392226Z",
     "shell.execute_reply.started": "2023-05-03T13:16:59.910785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  \n",
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "WARNING:tensorflow:TPU system local has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "print('Running on TPU ', tpu.master())\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
    "print(\"REPLICAS: \", tpu_strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True \n",
    "sess = tf.compat.v1.Session(config=config) \n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:21:47.831950Z",
     "iopub.status.busy": "2023-05-03T13:21:47.831271Z",
     "iopub.status.idle": "2023-05-03T13:21:47.836561Z",
     "shell.execute_reply": "2023-05-03T13:21:47.835341Z",
     "shell.execute_reply.started": "2023-05-03T13:21:47.831913Z"
    }
   },
   "outputs": [],
   "source": [
    "URL = \"https://raw.githubusercontent.com/nicknochnack/CommentToxicity/main/jigsaw-toxic-comment-classification-challenge/train.csv/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:21:51.709137Z",
     "iopub.status.busy": "2023-05-03T13:21:51.708758Z",
     "iopub.status.idle": "2023-05-03T13:21:55.250404Z",
     "shell.execute_reply": "2023-05-03T13:21:55.249337Z",
     "shell.execute_reply.started": "2023-05-03T13:21:51.709086Z"
    }
   },
   "outputs": [],
   "source": [
    "data =urllib.request.urlretrieve(URL, filename=\"toxic_comment_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:21:55.252425Z",
     "iopub.status.busy": "2023-05-03T13:21:55.252039Z",
     "iopub.status.idle": "2023-05-03T13:21:56.077591Z",
     "shell.execute_reply": "2023-05-03T13:21:56.076538Z",
     "shell.execute_reply.started": "2023-05-03T13:21:55.252394Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/working/toxic_comment_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T08:12:50.269702Z",
     "iopub.status.busy": "2023-05-03T08:12:50.268538Z",
     "iopub.status.idle": "2023-05-03T08:12:50.284500Z",
     "shell.execute_reply": "2023-05-03T08:12:50.283401Z",
     "shell.execute_reply.started": "2023-05-03T08:12:50.269661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic   \n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0  \\\n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T07:54:18.310251Z",
     "iopub.status.busy": "2023-05-03T07:54:18.309283Z",
     "iopub.status.idle": "2023-05-03T07:54:18.350807Z",
     "shell.execute_reply": "2023-05-03T07:54:18.349607Z",
     "shell.execute_reply.started": "2023-05-03T07:54:18.310195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T07:54:38.629572Z",
     "iopub.status.busy": "2023-05-03T07:54:38.629040Z",
     "iopub.status.idle": "2023-05-03T07:54:38.664330Z",
     "shell.execute_reply": "2023-05-03T07:54:38.663261Z",
     "shell.execute_reply.started": "2023-05-03T07:54:38.629534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    if data[column].dtype != 'O':\n",
    "        value_count = data[column].value_counts()\n",
    "        print(f\"{column} value count\\n{'--'*10}\")\n",
    "        print(f\"0: {value_count[0]} | {round((value_count[0]/data.shape[0])*100,2)} %\\n\"\n",
    "              f\"1: {value_count[1]} | {round((value_count[1]/data.shape[0])*100,2)} %\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text_len\"] = data[\"comment_text\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"text_len\"]==data[\"text_len\"].max()]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:22:07.019083Z",
     "iopub.status.busy": "2023-05-03T13:22:07.018507Z",
     "iopub.status.idle": "2023-05-03T13:22:07.035233Z",
     "shell.execute_reply": "2023-05-03T13:22:07.034171Z",
     "shell.execute_reply.started": "2023-05-03T13:22:07.019045Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data['comment_text']\n",
    "y = data[data.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:22:07.748214Z",
     "iopub.status.busy": "2023-05-03T13:22:07.747645Z",
     "iopub.status.idle": "2023-05-03T13:22:07.758848Z",
     "shell.execute_reply": "2023-05-03T13:22:07.757579Z",
     "shell.execute_reply.started": "2023-05-03T13:22:07.748177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "                                ...                        \n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T08:13:04.677476Z",
     "iopub.status.busy": "2023-05-03T08:13:04.676414Z",
     "iopub.status.idle": "2023-05-03T08:13:04.683757Z",
     "shell.execute_reply": "2023-05-03T08:13:04.682727Z",
     "shell.execute_reply.started": "2023-05-03T08:13:04.677439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:22:13.028492Z",
     "iopub.status.busy": "2023-05-03T13:22:13.027812Z",
     "iopub.status.idle": "2023-05-03T13:22:14.554860Z",
     "shell.execute_reply": "2023-05-03T13:22:14.553508Z",
     "shell.execute_reply.started": "2023-05-03T13:22:13.028454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet2022 to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet2022.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet2022')\n",
    "!cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:22:21.990028Z",
     "iopub.status.busy": "2023-05-03T13:22:21.989018Z",
     "iopub.status.idle": "2023-05-03T13:22:22.001272Z",
     "shell.execute_reply": "2023-05-03T13:22:22.000062Z",
     "shell.execute_reply.started": "2023-05-03T13:22:21.989984Z"
    }
   },
   "outputs": [],
   "source": [
    "class Text_Cleaner:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.STOPWORDS = stopwords.words('english')\n",
    "        self.wordnet = WordNetLemmatizer()\n",
    "        \n",
    "    def new_line_code(self, x:str)->str:\n",
    "        pattern = \"\\n\"\n",
    "        x = re.sub(pattern,' ', x).strip().lower()\n",
    "        return x\n",
    "\n",
    "    def remove_punctuations(self, x:str)->str:\n",
    "        x = x.translate(str.maketrans('','',string.punctuation))\n",
    "        return x\n",
    "\n",
    "    def remove_stopwords(self, x:str)->str:\n",
    "        sent=[]\n",
    "        for word in x.split():\n",
    "            if word not in self.STOPWORDS:\n",
    "                sent.append(word)\n",
    "        return ' '.join(sent)\n",
    "\n",
    "    def lemmatization(self, x:str)->str:\n",
    "        sent=[]\n",
    "        for word in x.split():\n",
    "            sent.append(self.wordnet.lemmatize(word))\n",
    "        return ' '.join(sent)\n",
    "    \n",
    "    def clean_text(self):\n",
    "        self.data = self.data.apply(self.new_line_code)\n",
    "        self.data = self.data.apply(self.remove_punctuations)\n",
    "        self.data = self.data.apply(self.remove_stopwords)\n",
    "        self.data = self.data.apply(self.lemmatization)\n",
    "        self.data = self.data.apply(lambda x: x.strip())\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:22:22.889587Z",
     "iopub.status.busy": "2023-05-03T13:22:22.889092Z",
     "iopub.status.idle": "2023-05-03T13:23:12.151425Z",
     "shell.execute_reply": "2023-05-03T13:23:12.150351Z",
     "shell.execute_reply.started": "2023-05-03T13:22:22.889541Z"
    }
   },
   "outputs": [],
   "source": [
    "X = Text_Cleaner(X).clean_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:23:12.153770Z",
     "iopub.status.busy": "2023-05-03T13:23:12.153369Z",
     "iopub.status.idle": "2023-05-03T13:23:12.163717Z",
     "shell.execute_reply": "2023-05-03T13:23:12.162586Z",
     "shell.execute_reply.started": "2023-05-03T13:23:12.153729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation edits made username hardcore metal...\n",
       "1         daww match background colour im seemingly stuc...\n",
       "2         hey man im really trying edit war guy constant...\n",
       "3         cant make real suggestion improvement wondered...\n",
       "4                       sir hero chance remember page thats\n",
       "                                ...                        \n",
       "159566    second time asking view completely contradicts...\n",
       "159567       ashamed horrible thing put talk page 128611993\n",
       "159568    spitzer umm there actual article prostitution ...\n",
       "159569    look like actually put speedy first version de...\n",
       "159570    really dont think understand came idea bad rig...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:23:40.900651Z",
     "iopub.status.busy": "2023-05-03T13:23:40.900270Z",
     "iopub.status.idle": "2023-05-03T13:23:40.906422Z",
     "shell.execute_reply": "2023-05-03T13:23:40.905260Z",
     "shell.execute_reply.started": "2023-05-03T13:23:40.900621Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    VOCAB_SIZE = 200000\n",
    "    OUTPUT_DIM = 1800\n",
    "    BUFFER_SIZE = 160000\n",
    "    BATCH_SIZE = 16*8\n",
    "    EPOCHS = 10\n",
    "    BASE_LOG_DIR = \"log_dir\"\n",
    "    CHECKPOINT_DIR = os.path.join(BASE_LOG_DIR,\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:23:41.870976Z",
     "iopub.status.busy": "2023-05-03T13:23:41.870595Z",
     "iopub.status.idle": "2023-05-03T13:23:42.338850Z",
     "shell.execute_reply": "2023-05-03T13:23:42.337828Z",
     "shell.execute_reply.started": "2023-05-03T13:23:41.870942Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(Config.BUFFER_SIZE)\n",
    "dataset = dataset.batch(Config.BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:23:45.050539Z",
     "iopub.status.busy": "2023-05-03T13:23:45.050169Z",
     "iopub.status.idle": "2023-05-03T13:23:45.061885Z",
     "shell.execute_reply": "2023-05-03T13:23:45.060740Z",
     "shell.execute_reply.started": "2023-05-03T13:23:45.050508Z"
    }
   },
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*0.8))\n",
    "val = dataset.skip(int(len(dataset)*0.8)).take(int(len(dataset)*0.2))\n",
    "#test = dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:11:08.999879Z",
     "iopub.status.busy": "2023-05-03T13:11:08.999471Z",
     "iopub.status.idle": "2023-05-03T13:11:09.026322Z",
     "shell.execute_reply": "2023-05-03T13:11:09.025093Z",
     "shell.execute_reply.started": "2023-05-03T13:11:08.999846Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=Config.VOCAB_SIZE,\n",
    "                               output_sequence_length=Config.OUTPUT_DIM,\n",
    "                               output_mode='int')\n",
    "vectorizer.adapt(X.values)\n",
    "#vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:23:50.940668Z",
     "iopub.status.busy": "2023-05-03T13:23:50.940301Z",
     "iopub.status.idle": "2023-05-03T13:23:50.947610Z",
     "shell.execute_reply": "2023-05-03T13:23:50.946564Z",
     "shell.execute_reply.started": "2023-05-03T13:23:50.940634Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(data):\n",
    "    vectorizer = TextVectorization(max_tokens=Config.VOCAB_SIZE,\n",
    "                               output_sequence_length=Config.OUTPUT_DIM,\n",
    "                               output_mode='int')\n",
    "    vectorizer.adapt(data.values)\n",
    "    #vectorized_text = vectorizer(X.values)\n",
    "    \n",
    "    LAYERS = [vectorizer,\n",
    "              Embedding(Config.VOCAB_SIZE+1, 32),\n",
    "              Bidirectional(LSTM(64, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)),\n",
    "              Bidirectional(LSTM(32)),\n",
    "              Dense(128, activation='relu'),\n",
    "              Dropout(0.1),\n",
    "              Dense(256, activation='relu'),\n",
    "              Dropout(0.1),\n",
    "              Dense(128, activation='relu'),\n",
    "              Dense(6, activation='sigmoid')]\n",
    "    \n",
    "    model = Sequential(LAYERS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:23:55.376183Z",
     "iopub.status.busy": "2023-05-03T13:23:55.375231Z",
     "iopub.status.idle": "2023-05-03T13:23:55.383753Z",
     "shell.execute_reply": "2023-05-03T13:23:55.382652Z",
     "shell.execute_reply.started": "2023-05-03T13:23:55.376100Z"
    }
   },
   "outputs": [],
   "source": [
    "def callbacks(base_dir=\".\"):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "    ckpt_file = os.path.join(Config.CHECKPOINT_DIR,\"model\")\n",
    "    os.makedirs(ckpt_file,exist_ok=True)\n",
    "\n",
    "    ckpt_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "      filepath = ckpt_file,\n",
    "      save_best_only = True)\n",
    "\n",
    "    callback_list = [early_stopping,\n",
    "                     ckpt_cb]\n",
    "    return callback_list\n",
    "callbacks_list = callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:23:56.462825Z",
     "iopub.status.busy": "2023-05-03T13:23:56.462258Z",
     "iopub.status.idle": "2023-05-03T13:24:18.107471Z",
     "shell.execute_reply": "2023-05-03T13:24:18.106476Z",
     "shell.execute_reply.started": "2023-05-03T13:23:56.462789Z"
    }
   },
   "outputs": [],
   "source": [
    "#with tpu_strategy.scope():\n",
    "model = create_model(X)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=AUC(multi_label=True, num_labels=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:24:20.991750Z",
     "iopub.status.busy": "2023-05-03T13:24:20.991374Z",
     "iopub.status.idle": "2023-05-03T13:24:21.028065Z",
     "shell.execute_reply": "2023-05-03T13:24:21.027294Z",
     "shell.execute_reply.started": "2023-05-03T13:24:20.991715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 1800)             0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 1800, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1800, 128)        49664     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,565,926\n",
      "Trainable params: 6,565,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:18:07.750753Z",
     "iopub.status.busy": "2023-05-03T13:18:07.749974Z",
     "iopub.status.idle": "2023-05-03T13:18:07.757190Z",
     "shell.execute_reply": "2023-05-03T13:18:07.756325Z",
     "shell.execute_reply.started": "2023-05-03T13:18:07.750717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T13:24:44.142769Z",
     "iopub.status.busy": "2023-05-03T13:24:44.142055Z",
     "iopub.status.idle": "2023-05-03T13:26:21.611363Z",
     "shell.execute_reply": "2023-05-03T13:26:21.609940Z",
     "shell.execute_reply.started": "2023-05-03T13:24:44.142730Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train, \n",
    "                    epochs=Config.EPOCHS,\n",
    "                    steps_per_epoch=len(train),\n",
    "                    validation_data=val,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T12:21:48.611614Z",
     "iopub.status.busy": "2023-05-03T12:21:48.610578Z",
     "iopub.status.idle": "2023-05-03T12:21:48.620183Z",
     "shell.execute_reply": "2023-05-03T12:21:48.618922Z",
     "shell.execute_reply.started": "2023-05-03T12:21:48.611571Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_evaluation(model, vectorizer: TextVectorization, pred_data: pd.Series, y_true):\n",
    "    #pred_data = Text_Cleaner(pred_data).clean_text()\n",
    "    #vectorized_text = vectorizer(pred_data)\n",
    "    y_pred = model.predict(pred_data)\n",
    "    try:\n",
    "        precision = precision_score(y_true, (y_pred>0.5).astype(int), average=\"macro\")\n",
    "        recall = recall_score(y_true, (y_pred>0.5).astype(int), average=\"macro\")\n",
    "        f1 = f1_score(y_true, (y_pred>0.5).astype(int), average=\"macro\")\n",
    "        auc = roc_auc_score(y_true, y_pred, average=\"macro\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    print(f\"Precision: {precision}\\n\"\n",
    "          f\"Recall: {recall}\\n\"\n",
    "          f\"F1-Score: {f1}\\n\"\n",
    "          f\"ROC-AUC-Score: {auc}\")\n",
    "    return (precision, recall, f1, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate([x for x, y in train])\n",
    "y_train = np.concatenate([y for x, y in train])\n",
    "result_train=model_evaluation(model=model, vectorizer=vectorizer, pred_data=x_train, y_true=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_val = np.concatenate([x for x, y in val])\n",
    "y_val = np.concatenate([y for x, y in val])\n",
    "result_train=model_evaluation(model=model, vectorizer=vectorizer, pred_data=x_val, y_true=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
